{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PGpw2d-RlQy"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhDIgfeHSkbr",
        "outputId": "4f9f1544-5cdd-447d-b25c-34cc223f9cb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ],
      "metadata": {
        "id": "QEaHowFXT66f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Corpus and Corpora"
      ],
      "metadata": {
        "id": "cJUw73KGY50q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Corpus **bold text** : Kullandığımız metinlere verilen isimdir.\n",
        "* Corpora **bold text** : Corpus'un çoğul haline denir."
      ],
      "metadata": {
        "id": "ITXKQO7YY9Rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://tr.wikipedia.org/wiki/Alan_Turing\n",
        "data = \"Alan Turing, İngiliz matematikçi, bilgisayar bilimcisi ve kriptolog. Bilgisayar biliminin kurucusu sayılır. Geliştirmiş olduğu Turing testi ile makinelerin ve bilgisayarların düşünme yetisine sahip olup olamayacakları konusunda bir kriter öne sürmüştür.\"\n",
        "\n",
        "corpus = \"AISeclab is an organization that works on artificial intelligence and cybersecurity.\"\n",
        "corpus1 = \"NLTK is library to use for nlp. It has functions to process corpus and corpora.\""
      ],
      "metadata": {
        "id": "O53Akku8SnVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTYexsMBT_JF",
        "outputId": "4116aec2-4edf-4a43-d0d0-dc96f3dddb90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Alan',\n",
              " 'Turing,',\n",
              " 'İngiliz',\n",
              " 'matematikçi,',\n",
              " 'bilgisayar',\n",
              " 'bilimcisi',\n",
              " 've',\n",
              " 'kriptolog.',\n",
              " 'Bilgisayar',\n",
              " 'biliminin',\n",
              " 'kurucusu',\n",
              " 'sayılır.',\n",
              " 'Geliştirmiş',\n",
              " 'olduğu',\n",
              " 'Turing',\n",
              " 'testi',\n",
              " 'ile',\n",
              " 'makinelerin',\n",
              " 've',\n",
              " 'bilgisayarların',\n",
              " 'düşünme',\n",
              " 'yetisine',\n",
              " 'sahip',\n",
              " 'olup',\n",
              " 'olamayacakları',\n",
              " 'konusunda',\n",
              " 'bir',\n",
              " 'kriter',\n",
              " 'öne',\n",
              " 'sürmüştür.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenization"
      ],
      "metadata": {
        "id": "znb_fHxZYPCO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Kelime Ayırma"
      ],
      "metadata": {
        "id": "h7Q4yOFEYLJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(corpus)"
      ],
      "metadata": {
        "id": "z1-6bxPeUAAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-X2dcHLZ8kY",
        "outputId": "93bb4c08-3487-4334-bfaf-b3654f34d6f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AISeclab',\n",
              " 'is',\n",
              " 'an',\n",
              " 'organization',\n",
              " 'that',\n",
              " 'works',\n",
              " 'on',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " 'and',\n",
              " 'cybersecurity',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cümle Ayırma"
      ],
      "metadata": {
        "id": "40PMBOmCYXat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98hSM3IDUoka",
        "outputId": "d85bc599-dd79-47ae-d8c8-3d9d033b5771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Alan Turing, İngiliz matematikçi, bilgisayar bilimcisi ve kriptolog.',\n",
              " 'Bilgisayar biliminin kurucusu sayılır.',\n",
              " 'Geliştirmiş olduğu Turing testi ile makinelerin ve bilgisayarların düşünme yetisine sahip olup olamayacakları konusunda bir kriter öne sürmüştür.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in word_tokenize(data):\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJnCfvVDVLcq",
        "outputId": "e4527b76-be66-46f2-c428-8f9922a4e05e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alan\n",
            "Turing\n",
            ",\n",
            "İngiliz\n",
            "matematikçi\n",
            ",\n",
            "bilgisayar\n",
            "bilimcisi\n",
            "ve\n",
            "kriptolog\n",
            ".\n",
            "Bilgisayar\n",
            "biliminin\n",
            "kurucusu\n",
            "sayılır\n",
            ".\n",
            "Geliştirmiş\n",
            "olduğu\n",
            "Turing\n",
            "testi\n",
            "ile\n",
            "makinelerin\n",
            "ve\n",
            "bilgisayarların\n",
            "düşünme\n",
            "yetisine\n",
            "sahip\n",
            "olup\n",
            "olamayacakları\n",
            "konusunda\n",
            "bir\n",
            "kriter\n",
            "öne\n",
            "sürmüştür\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Stop Words : Cümle İçinde Etki Etmeyen Kelimeler\n"
      ],
      "metadata": {
        "id": "0mu0zem5W8gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "FVz518nXW-cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lzd5JHIvW_iS",
        "outputId": "6ace7c5b-f048-4b0f-db36-7e25e600490d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "5ivMeXOPXCrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = \"\""
      ],
      "metadata": {
        "id": "qWVLs40_XJck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwordsEN = stopwords.words(\"english\")"
      ],
      "metadata": {
        "id": "ms49yCtlXKjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwordsEN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ha4P1BVtXPRe",
        "outputId": "601c7248-a8e6-480b-d632-4956f4bf14dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(stopwordsEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoxP1sEbXQPk",
        "outputId": "026b2661-6b03-4e9c-eaea-82b71d06ffe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwordsTR = stopwords.words(\"turkish\")"
      ],
      "metadata": {
        "id": "4nD6sPT0XSVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwordsTR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccSPjRDgXX_F",
        "outputId": "b217d3a2-a4ed-411b-898e-bed511ffad5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['acaba',\n",
              " 'ama',\n",
              " 'aslında',\n",
              " 'az',\n",
              " 'bazı',\n",
              " 'belki',\n",
              " 'biri',\n",
              " 'birkaç',\n",
              " 'birşey',\n",
              " 'biz',\n",
              " 'bu',\n",
              " 'çok',\n",
              " 'çünkü',\n",
              " 'da',\n",
              " 'daha',\n",
              " 'de',\n",
              " 'defa',\n",
              " 'diye',\n",
              " 'eğer',\n",
              " 'en',\n",
              " 'gibi',\n",
              " 'hem',\n",
              " 'hep',\n",
              " 'hepsi',\n",
              " 'her',\n",
              " 'hiç',\n",
              " 'için',\n",
              " 'ile',\n",
              " 'ise',\n",
              " 'kez',\n",
              " 'ki',\n",
              " 'kim',\n",
              " 'mı',\n",
              " 'mu',\n",
              " 'mü',\n",
              " 'nasıl',\n",
              " 'ne',\n",
              " 'neden',\n",
              " 'nerde',\n",
              " 'nerede',\n",
              " 'nereye',\n",
              " 'niçin',\n",
              " 'niye',\n",
              " 'o',\n",
              " 'sanki',\n",
              " 'şey',\n",
              " 'siz',\n",
              " 'şu',\n",
              " 'tüm',\n",
              " 've',\n",
              " 'veya',\n",
              " 'ya',\n",
              " 'yani']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(stopwordsTR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kI6TFT0XtIK",
        "outputId": "6ef8b450-d3c2-45f8-9711-0d30adfffc55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_corpus = \" \".join(word for word in tokens if word not in stopwordsEN)"
      ],
      "metadata": {
        "id": "50-TfJ4AXt9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "O35MobgPZq3X",
        "outputId": "1d03e5fd-c342-4c7d-9fd4-97905e7e6d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AISeclab organization works artificial intelligence cybersecurity .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sayıları ve Özel Karakterleri Kaldırmak"
      ],
      "metadata": {
        "id": "gTD0V5tQaimA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "DW3pEJBWZrQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \\d sayıları belirten regex ifadesi\n",
        "# \\w kelimeleri - \\W kelime olmayanları temsil eder.\n",
        "\n",
        "examp1 = \"This is a test message. 123**()\"\n",
        "examp1 = re.sub(r\"\\W+\", \" \", examp1)"
      ],
      "metadata": {
        "id": "H9tNSYDeanIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(examp1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQpRiPKobe_Q",
        "outputId": "6f454afd-c23c-4933-fdcb-1cc885cf0994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a test message 123 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examp1 = re.sub(r\"\\d+\", \" \", examp1)\n"
      ],
      "metadata": {
        "id": "ZFSXclSAbfmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(examp1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl0R9qFEbtyZ",
        "outputId": "2afe0def-e76a-4031-8c4d-ca28fb8b3239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a test message   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_corpus += \" 234 %+^^%+\\ /*+-\""
      ],
      "metadata": {
        "id": "JfQqgGDfcbcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_corpus = clean_corpus.lower()\n",
        "clean_corpus = re.sub(r\"\\W+\", \" \", clean_corpus)\n",
        "clean_corpus = re.sub(r\"\\d+\", \" \", clean_corpus)"
      ],
      "metadata": {
        "id": "6FKIBPSVbu2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SCzuQt-GcFn7",
        "outputId": "cc378fc7-79f9-455e-af62-67859224494f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'aiseclab organization works artificial intelligence cybersecurity   '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming\n",
        "* Kelimelerin eklerini kaldırır."
      ],
      "metadata": {
        "id": "LZyNUWpadEgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "clean_corpus_tokens = nltk.word_tokenize(clean_corpus)\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "3nTj8zlCcHy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p3axOvndde4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"drive\", \"driving\", \"driver\", \"drives\", \"drove\", \"cat\", \"children\"]\n",
        "for word in words:\n",
        "  print(word + \": \" + stemmer.stem(word))\n",
        "\n",
        "print(\" \")\n",
        "for word in clean_corpus_tokens:\n",
        "  print(word + \": \" + stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMu4f6YddUhG",
        "outputId": "00ebac91-18e9-4f2a-d398-05833ad0fe2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive: drive\n",
            "driving: drive\n",
            "driver: driver\n",
            "drives: drive\n",
            "drove: drove\n",
            "cat: cat\n",
            "children: children\n",
            " \n",
            "aiseclab: aiseclab\n",
            "organization: organ\n",
            "works: work\n",
            "artificial: artifici\n",
            "intelligence: intellig\n",
            "cybersecurity: cybersecur\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmazation\n",
        "\n",
        "* Kelimelerin köklerini alır."
      ],
      "metadata": {
        "id": "GSme5JTGeAvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag.brill import Word\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9JOvxucd2Bc",
        "outputId": "bc15af61-7285-45ed-b955-e1b5106526a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"drive\", \"driving\", \"driver\", \"drives\", \"drove\", \"cat\", \"children\"]\n",
        "for word in words:\n",
        "  print(word + \" \" + lemmatizer.lemmatize(word))\n",
        "\n",
        "print(\" \")\n",
        "\n",
        "for word in words:\n",
        "  print(word + \" \" + lemmatizer.lemmatize(word, pos=\"v\"))\n",
        "\n",
        "print(\" \")\n",
        "\n",
        "for word in clean_corpus_tokens:\n",
        "  print(word + \" \" + lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Fe72YU2eSoI",
        "outputId": "473506e1-9fe2-4bd1-d9bc-83e756318ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive drive\n",
            "driving driving\n",
            "driver driver\n",
            "drives drive\n",
            "drove drove\n",
            "cat cat\n",
            "children child\n",
            " \n",
            "drive drive\n",
            "driving drive\n",
            "driver driver\n",
            "drives drive\n",
            "drove drive\n",
            "cat cat\n",
            "children children\n",
            " \n",
            "aiseclab aiseclab\n",
            "organization organization\n",
            "works work\n",
            "artificial artificial\n",
            "intelligence intelligence\n",
            "cybersecurity cybersecurity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WNEt3v_4elAn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}